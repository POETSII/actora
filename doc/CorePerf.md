Modern computers spend huge numbers of transistors on the
identification of instruction-level parallelism and the
provision of coherent shared memories.  But for applications
conforming to the actor model, parallelism is abundant, blindingly
explicit, and without shared state.

On POETS, we are exploring the design of a new kind of machine to
support the actor model more directly.  Here we focus on Erlang, one
of the most successfull realisations of the actor model to date.  The
key idea is to use a very large number of very simple cores.  The
first question, which we address below, is: *what does a simple Erlang
core look like?*

We explore two approaches:

  1. A compiler from a subset of Erlang called
     [Elite](https://github.com/POETSII/elite) down to a tiny
     RISC core called NIOS-II (**Elite C Backend**).

  2. The development of a custom stack processor for Elite (**Elite Core**).

## 1. Elite C Backend

This is a C code generator that performs a like-for-like mapping from
Erlang functions to C functions, and from Erlang variables to C
variables.  As a result, it is both simple and efficient, exploiting
the optimisation capabilities of the C compiler, such as tail-call
optimisation, inlining, common subexpression elimination, and many
more.  However, a big drawback of the approach is that the garbage
collector must be *conservative* since pointers and integers cannot be
distinguished in C.  This also means that the garbage collector cannot
relocate objects, preventing the use of copying collectors, operating
in O(survivors) time, that work well for functional languages.  The
generated C code runs on both x86 and NIOS-II architectures.

## 2. Elite Core

This is a simple [stack machine](/doc/ISA.md) with a 3-stage pipeline
(Fetch, Decode, Execute).  It has separate memories for instructions,
stack data, and heap data.  The stack is implemented using a dual-port
RAM, allowing two stack elements to be accessed per cycle.  The heap
memory is two cells wide, since almost all heap objects contain at
least two cells.  Cells on the stack and heap are both tagged with
type information.  The tags of pointer cells contain further
information about the object pointed-to, such as its length and arity
(if it is a closure), often allowing patterns to be matched and types
to be checked without having to dereference. The core supports all the
ALU primitives available on the NIOS-II.  It also includes a fast
copying garbage collector, implemented as a small state-machine in
hardware.  The compiler from Elite to stack code is small and
straightforward.

## 3. Benchmarks

The following benchmarks are mostly representative of symbolic
functional programs, with plenty of pattern matching, recursion,
dynamic and persistent data structures.  One exception is *shiftsub*,
which is a tight tail-recursive loop with only primitive operations,
and should strongly favour a register machine.

Benchmark | Description
--------- | -----------
[fib](/benchmarks/fib.erl) | Standard doubly-recursive fibonacci function
[adjoxo](/benchmarks/adjoxo.erl) | Adjudicator for naughts and crosses, involving sets as lists
[mss](/benchmarks/mss.erl) | Basic maximum segment sum function on lists
[redblack](/benchmarks/redblack.erl) | Insertion and membership functions on Red-Black trees
[while](/benchmarks/while.erl) | Operational semantics for a simple imperative language
[braun](/benchmarks/braun.erl) | Insertion and flattening functions on Braun trees
[queens](/benchmarks/queens.erl) | N-queens solver using success/fail continuation passing style
[shiftsub](/benchmarks/shiftsub.erl) | Binary long division

## 4. HIPE v. Elite C Backend

We would like to use code generated by the Elite C Backend running on
the NIOS-II as a baseline to compare the performance the Elite Core.
Before that, it is useful to establish whether the Elite C Backend is
actually representative of the performance of existing Erlang
compilers.  We do this by comparing against **HIPE**, the
high-performance Erlang compiler, on an x86 machine.

Benchmark | HIPE (s) | Elite C backend (s) | GC (%) | Speedup
--------- | ----:    | -----:              | -----: | ------:
fib       | 1.06     |  1.02               | 0      |  1.03
adjoxo    | 0.40     |  0.39               | 38.40  |  1.02
mss       | 0.71     |  0.24               | 0.01   |  2.95
redblack  | 0.35     |  0.37               | 30.00  |  0.94
while     | 0.27     |  0.34               | 50.00  |  0.79
braun     | 0.21     |  0.33               | 45.45  |  0.63
queens    | 0.72     |  0.29               | 0.03   |  2.48
shiftsub  | 0.85     |  0.11               | 0      |  7.72

These results were obtained from an `Intel(R) Core(TM) i7-6770HQ CPU @
2.60GHz`.  The Elite C backend was given a 1MB heap.  The GC column
shows the proportion of time spent in the garbage collector
for the Elite C backend, not HIPE.

The results show that the Elite C backend is generally more efficient
than HIPE.  It falls slightly short only in the heap-intensive
benchmarks, were GC time (a known weakness) is significant.  It is
possible that we could improve GC time by using LLVM as a target
instead of C (allowing pointers and integers to be distinguished).

## 5. Elite C Backend v. Elite Core

The Elite Core is slightly larger than a NIOS-II, and has a lower Fmax:

Implementation | DE5-Net Area (ALMs) | DE5-Net FMax (MHz)
-------------- | -----------------:  | -----------------:
NIOS-II        | 850                 | 323
Elite core     | 1087                | 254     

Despite the lower Fmax, the Elite Core offers a slight performance
improvement (both implementations use a 56KB heap):

Benchmark | NIOS-II (s) | GC (%) | Elite core (s) | %GC    | Speedup
--------- | ----------: | -----: | -------------: | -----: | ------:
fib       |   35.92     |      0 |  18.90         |     0  |  1.90
adjoxo    |   11.42     |  41.70 |   3.99         |  2.35  |  2.86
mss       |    7.81     |   1.97 |   4.73         |  0.23  |  1.65
redblack  |   11.26     |  39.47 |   4.86         |  7.87  |  2.31
while     |   12.12     |  42.65 |   3.30         |  2.31  |  3.67
braun     |   11.97     |  55.40 |   2.92         | 15.10  |  4.10
queens    |    7.89     |   3.80 |   6.09         |  0.10  |  1.30
shiftsub  |    4.04     |      0 |   4.76         |     0  |  0.85

Again, the difference is most visible in the benchmarks where GC time
is significant, which is a known weakness of the C backend (which
could probably be improved using a more sophisticated LLVM backend
instead).

The Elite Core is quite a modest attempt at a language-specific CPU in
the sense that aims to keep logic usage down -- we want to fit as many
instances of this core on an FPGA as we can.  But that goal has
resulted in only a modest performance improvement over a
space-optimised RISC core.
